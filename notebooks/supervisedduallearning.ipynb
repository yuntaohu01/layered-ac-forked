{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: load folder from google drive folder layered-ac-main\n",
    "\n",
    "import os\n",
    "\n",
    "# Replace 'layered-ac-main' with the actual folder name in your Google Drive\n",
    "folder_path = '/content/drive/My Drive/layered-ac-main'\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "# Check if the folder exists\n",
    "if os.path.exists(folder_path):\n",
    "  # List the contents of the folder\n",
    "  print(f\"Contents of '{folder_path}':\")\n",
    "  for item in os.listdir(folder_path):\n",
    "    print(item)\n",
    "else:\n",
    "  print(f\"Folder '{folder_path}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear with lqr tracking contoller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.dynamics.linear import LinearDynamics\n",
    "from controller.ilqrtrackingctrl import ILQRtrackingcontroller\n",
    "from numlp import NuMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system dynamics (Double Integrator Model)\n",
    "dt = 0.1\n",
    "A = np.array([[1, 0, dt, 0],\n",
    "              [0, 1, 0, dt],\n",
    "              [0, 0, 1, 0],\n",
    "              [0, 0, 0, 1]])\n",
    "\n",
    "B = np.array([[0, 0],\n",
    "              [0, 0],\n",
    "              [dt, 0],\n",
    "              [0, dt]])\n",
    "\n",
    "dynamics = LinearDynamics(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cost matrices for LQ Tracking Controller\n",
    "Q = np.diag(np.array([1, 1, 0, 0]))\n",
    "Qf = Q * 10\n",
    "R = np.eye(2) * 0.1\n",
    "controller = ILQRtrackingcontroller(dynamics, Q, R, Qf, dt=dt, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate random reference trajectories\n",
    "def generate_reference_trajectories(batch_size, T, step_length= 0.1):\n",
    "    \"\"\" Generate batch of reference trajectories\n",
    "    Returns:\n",
    "    r_traj: (batch_size, T, Nx)\n",
    "    \"\"\"\n",
    "    Nx = 4  # [x, y, vx, vy]\n",
    "    r_traj = torch.zeros(batch_size, T, Nx, device=device)\n",
    "    # Random initial positions\n",
    "    x0 = torch.rand(batch_size, 2, device=device) * 1.0  # positions in [0,1)\n",
    "    # Random initial velocities\n",
    "    v0 = torch.zeros(batch_size, 2, device=device)\n",
    "    # Generate random increments\n",
    "    for i in range(batch_size):\n",
    "        pos = x0[i]\n",
    "        vel = v0[i]\n",
    "        r_traj[i, 0, :2] = pos\n",
    "        r_traj[i, 0, 2:] = vel \n",
    "        for t in range(1, T):\n",
    "            # Random increments/decrements within step_length\n",
    "            delta_pos = (torch.rand(2, device=device) - 0.5) * 2 * step_length\n",
    "            pos = pos + delta_pos\n",
    "            r_traj[i, t, :2] = pos\n",
    "            r_traj[i, t, 2:] = vel  # Keep velocity zero for simplicity\n",
    "    return r_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(batch_size, T, dynamics, controller):\n",
    "    \"\"\" Generate training data\n",
    "    Returns:\n",
    "    x_t: (batch_size, Nx)\n",
    "    delta_r: (batch_size, Nx)\n",
    "    \"\"\"\n",
    "    # Generate reference trajectories\n",
    "    r_traj = generate_reference_trajectories(batch_size, T + 1)\n",
    "    # Initial states x0 = zeros\n",
    "    x0 = torch.zeros(batch_size, dynamics.Nx, device=device)\n",
    "\n",
    "    # Reference of control output is setting to be zero defaultly\n",
    "    u_ref_traj = torch.zeros(batch_size, T, Nu, device=device)\n",
    "    u0 = torch.zeros(batch_size, T, Nu, device=device)\n",
    "    \n",
    "    # Use controller to get control inputs\n",
    "    u_exac, x_exac = controller.solve(x0, u0, r_traj, u_ref_traj) \n",
    "\n",
    "    # Compute delta_r = r_t - x_t\n",
    "    delta_r = r_traj - x_exac\n",
    "\n",
    "    return r_traj, delta_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 20\n",
    "# Define neural network parameters\n",
    "input_size = dynamics.Nx * (T + 1)  # Flattened reference trajectory\n",
    "output_size = dynamics.Nx * (T + 1) # Flattened delta_r over the T\n",
    "hidden_size = 128  # You can adjust this based on your requirements\n",
    "\n",
    "# Initialize the neural network model\n",
    "model = NuMLP(input_size, output_size, hidden_size=hidden_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the helper class\n",
    "helper = NuMLPHelper(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    dynamics=dynamics,\n",
    "    controller=controller,\n",
    "    T=T,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "# Train the model\n",
    "helper.train_model(\n",
    "    num_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    generate_training_data_func=generate_training_data,\n",
    "    checkpoint_interval=10  # Save model every 10 epochs\n",
    ")\n",
    "\n",
    "# Validate the model\n",
    "helper.validate_model(\n",
    "    batch_size=batch_size,\n",
    "    generate_training_data_func=generate_training_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicycle with ? tracking contoller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.dynamics.unicycle import UnicycleDynamics\n",
    "from controller.lqtrackingController import LQTrackingController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters\n",
    "batch_size = 64\n",
    "sequence_length = 20  # Time steps\n",
    "dt = 0.1  # Time step size\n",
    "\n",
    "def sample_reference_points(batch_size, sequence_length):\n",
    "    # Random initial positions x and y\n",
    "    x0 = torch.randn(batch_size, 1).to(device)\n",
    "    y0 = torch.randn(batch_size, 1).to(device)\n",
    "\n",
    "    # Random increments/decrements within step length\n",
    "    dx = torch.randn(batch_size, sequence_length) * dt\n",
    "    dy = torch.randn(batch_size, sequence_length) * dt\n",
    "\n",
    "    # Cumulative sum to get positions over time\n",
    "    x_refs = x0 + torch.cumsum(dx, dim=1)\n",
    "    y_refs = y0 + torch.cumsum(dy, dim=1)\n",
    "    \n",
    "    # Stack x and y references to create reference trajectory\n",
    "    r_refs = torch.stack([x_refs, y_refs], dim=-1)  # Shape: (batch_size, sequence_length, 2)\n",
    "    \n",
    "    return r_refs  # Shape: (batch_size, sequence_length, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exact_trajectories(r_refs, x_0 = torch.zeros(1, dynamics.Nx)):\n",
    "    \n",
    "    batch_size, sequence_length, _ = r_refs.shape\n",
    "    x_trajs = []\n",
    "    u_trajs = []\n",
    "    \n",
    "    # Initialize the state tensor\n",
    "    x0 = torch.zeros(batch_size, dynamics.Nx).to(device)  # Shape: (batch_size, Nx)\n",
    "    \n",
    "    # Concatenate x0 and r_refs along time dimension\n",
    "    x0_r_refs = torch.cat([x0.unsqueeze(1), r_refs], dim=1)  # Shape: (batch_size, T + 1, Nx)\n",
    "    \n",
    "    # Flatten along the time dimension\n",
    "    x0_r_refs_flat = x0_r_refs.reshape(batch_size, -1)  # Shape: (batch_size, Nx * (T + 1))\n",
    "    \n",
    "    # Get control inputs from the controller\n",
    "    u_trajs_flat = controller.control(x0_r_refs_flat)  # Should return control inputs over the T\n",
    "    u_trajs = u_trajs_flat.reshape(batch_size, sequence_length, -1)  # Shape: (batch_size, sequence_length, Nu)\n",
    "    \n",
    "    # Simulate the dynamics over the T\n",
    "    x_trajs = [x0.unsqueeze(1)]  # List to collect state trajectories, start with x0\n",
    "    x_curr = x0\n",
    "    for t in range(sequence_length):\n",
    "        u_curr = u_trajs[:, t, :]  # Shape: (batch_size, Nu)\n",
    "        x_next = dynamics.step(x_curr, u_curr)  # Shape: (batch_size, Nx)\n",
    "        x_trajs.append(x_next.unsqueeze(1))  # Add the next state\n",
    "        x_curr = x_next  # Update current state\n",
    "    \n",
    "    # Concatenate along the time dimension, excluding the initial state\n",
    "    x_trajs = torch.cat(x_trajs[1:], dim=1)  # Shape: (batch_size, sequence_length, Nx)\n",
    "    \n",
    "    return x_trajs  # Shape: (batch_size, sequence_length, Nx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NuNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NuNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the trajectories for the network\n",
    "def prepare_data(x_trajs, r_refs):\n",
    "    # x_trajs and r_refs shape: (batch_size, sequence_length, Nx)\n",
    "    x_inputs = x_trajs.reshape(-1, dynamics.Nx)\n",
    "    nu_targets = (r_refs.reshape(-1, dynamics.Nx) - x_inputs)\n",
    "    return x_inputs, nu_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the classes are implemented and imported\n",
    "dynamics = UnicycleDynamics(dt=dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = UnicyclePDController(dt=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial position assume start from (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Initialize the helper class\n",
    "    helper = NuMLPHelper(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        dynamics=dynamics,\n",
    "        controller=controller,\n",
    "        horizon=horizon,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Training parameters\n",
    "    num_epochs = 50\n",
    "    batch_size = 64\n",
    "\n",
    "    # Train the model\n",
    "    helper.train_model(\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        generate_training_data_func=generate_training_data,\n",
    "        checkpoint_interval=10  # Save model every 10 epochs\n",
    "    )\n",
    "\n",
    "    # Validate the model\n",
    "    helper.validate_model(\n",
    "        batch_size=batch_size,\n",
    "        generate_training_data_func=generate_training_data\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
